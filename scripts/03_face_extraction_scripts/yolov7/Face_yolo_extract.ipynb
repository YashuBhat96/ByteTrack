{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ybr5070\\AppData\\Local\\anaconda3\\envs\\yolo_env\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: R01_090_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 21345\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 21345: 711.4666666666667\n",
      "Finished processing R01_090_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_093_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 21394\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 21394: 713.1\n",
      "Finished processing R01_093_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_095_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 35633\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 35633: 1187.7333333333333\n",
      "Finished processing R01_095_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_096_V2_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 71100\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 71100: 2369.9666666666667\n",
      "Finished processing R01_096_V2_PS4_fixed.mp4.\n",
      "Processing video: R01_098_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 11916\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 11916: 397.1666666666667\n",
      "Finished processing R01_098_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_101_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 28945\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 28945: 964.8\n",
      "Finished processing R01_101_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_103_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 43593\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 43593: 1453.0666666666666\n",
      "Finished processing R01_103_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_104_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 56850\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 56850: 1894.9666666666667\n",
      "Finished processing R01_104_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_105_V2_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 63071\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 63071: 2102.3333333333335\n",
      "Finished processing R01_105_V2_PS4_fixed.mp4.\n",
      "Processing video: R01_106_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55361\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55361: 1845.3333333333333\n",
      "Finished processing R01_106_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_107_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 28349\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 28349: 944.9333333333333\n",
      "Finished processing R01_107_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_109_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55549\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55549: 1851.6\n",
      "Finished processing R01_109_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_110_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 54062\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 54062: 1802.0333333333333\n",
      "Finished processing R01_110_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_111_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 29630\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 29630: 987.6333333333333\n",
      "Finished processing R01_111_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_113_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55195\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55195: 1839.8\n",
      "Finished processing R01_113_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_114_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 27406\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 27406: 913.5\n",
      "Finished processing R01_114_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_115_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 56261\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 56260: 1875.3\n",
      "Finished processing R01_115_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_116_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 56372\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 56372: 1879.0333333333333\n",
      "Finished processing R01_116_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_117_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 54180\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 54180: 1805.9666666666667\n",
      "Finished processing R01_117_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_118_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55534\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55534: 1851.1\n",
      "Finished processing R01_118_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_119_V2_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55397\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55397: 1846.5333333333333\n",
      "Finished processing R01_119_V2_PS4_fixed.mp4.\n",
      "Processing video: R01_120_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 27579\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 27579: 919.2666666666667\n",
      "Finished processing R01_120_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_121_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 37619\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 37619: 1253.9333333333334\n",
      "Finished processing R01_121_V4_PS4_fixed.mp4.\n",
      "Processing video: R01_122_V3_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 31602\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 31602: 1053.3666666666666\n",
      "Finished processing R01_122_V3_PS4_fixed.mp4.\n",
      "Processing video: R01_123_V2_ps4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55493\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55493: 1849.7333333333333\n",
      "Finished processing R01_123_V2_ps4_fixed.mp4.\n",
      "Processing video: R01_124_V2_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 32386\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 32386: 1079.5\n",
      "Finished processing R01_124_V2_PS4_fixed.mp4.\n",
      "Processing video: R01_125_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 26149\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 26149: 871.6\n",
      "Finished processing R01_125_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_126_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 43786\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 43786: 1459.5\n",
      "Finished processing R01_126_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_127_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 14695\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 14695: 489.8\n",
      "Finished processing R01_127_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_128_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 19277\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 19277: 642.5333333333333\n",
      "Finished processing R01_128_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_129_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 26525\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 26525: 884.1333333333333\n",
      "Finished processing R01_129_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_130_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 42226\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 42226: 1407.5\n",
      "Finished processing R01_130_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_131_V5_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 29899\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 29899: 996.6\n",
      "Finished processing R01_131_V5_PS4_fixed.mp4.\n",
      "Processing video: R01_132_V4_PS4 _fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 55298\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 55298: 1843.2333333333333\n",
      "Finished processing R01_132_V4_PS4 _fixed.mp4.\n",
      "Processing video: R01_133_V4_PS4_fixed.mp4\n",
      "Frame Count (CAP_PROP_FRAME_COUNT): 91356\n",
      "detect_and_track called\n",
      "Last timestamp processed for frame 91356: 3045.1666666666665\n",
      "Finished processing R01_133_V4_PS4_fixed.mp4.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\ybr5070\\yolov7\")  # Update with your actual path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import winsound\n",
    "\n",
    "from models.experimental import attempt_load  # For YOLOv7 model loading\n",
    "from utils.general import non_max_suppression  # For YOLOv7 post-processing\n",
    "from collections import deque\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "def get_frame_timestamps(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_timestamps = {i: i / fps for i in range(frame_count)}\n",
    "    cap.release()\n",
    "    return frame_timestamps\n",
    "\n",
    "def clean_path(path):\n",
    "    return \"\\\\\".join([part.strip() for part in path.split(\"\\\\\")])\n",
    "\n",
    "save_base_dir = clean_path(r\"C:\\Users\\ybr5070\\Desktop\\yolo_face\\PS4\")\n",
    "\n",
    "def save_tracked_image(frame, bbox, output_dir, timestamp):\n",
    "    try:\n",
    "        if bbox is not None:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            roi_frame = frame[y:y+h, x:x+w]\n",
    "            if roi_frame.size > 0:\n",
    "                roi_frame_resized = cv2.resize(roi_frame, (224, 224))  # Resize to 224x224\n",
    "                filename = f\"tracked_{timestamp:.2f}.jpg\"\n",
    "                filepath = clean_path(os.path.join(output_dir, filename))\n",
    "                success = cv2.imwrite(filepath, roi_frame_resized)\n",
    "                if not success:\n",
    "                    raise Exception(\"cv2.imwrite returned False\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while saving image: {e}\")\n",
    "\n",
    "def process_frame(frame, target_size=(512, 320)):\n",
    "    frame_resized = cv2.resize(frame, target_size)\n",
    "    tensor_frame = F.to_tensor(frame_resized).unsqueeze(0).cuda()\n",
    "    return tensor_frame, frame_resized\n",
    "\n",
    "def initialize_kalman_filter():\n",
    "    kf = KalmanFilter(\n",
    "        transition_matrices=[[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]],\n",
    "        observation_matrices=[[1, 0, 0, 0], [0, 1, 0, 0]],\n",
    "    )\n",
    "    return kf\n",
    "\n",
    "def update_kalman(kf, state_mean, state_covariance, observation):\n",
    "    state_mean, state_covariance = kf.filter_update(\n",
    "        filtered_state_mean=state_mean,\n",
    "        filtered_state_covariance=state_covariance,\n",
    "        observation=observation\n",
    "    )\n",
    "    return state_mean, state_covariance\n",
    "\n",
    "def detect_and_track(video_path, model, output_dir, timestamps, redetect_interval=10, target_size=(512, 320), detection_threshold=0.2, nms_threshold=0.8, confidence_boost_threshold=5):\n",
    "    print(\"detect_and_track called\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "    kf = initialize_kalman_filter()  # Initialize Kalman Filter\n",
    "    init_tracking = False\n",
    "    frame_count = 0\n",
    "    label = \"\"\n",
    "    screen_width, screen_height = 1366, 768  # Set display size\n",
    "    tracked_confidence = 0\n",
    "    tracking_stability = 0\n",
    "    track_history = deque(maxlen=10)  # History for trajectory prediction\n",
    "    state_mean = None\n",
    "    state_covariance = np.eye(4)\n",
    "    padding = 5\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        timestamp = timestamps[frame_count]\n",
    "\n",
    "        if frame_count % redetect_interval == 0 or not init_tracking:\n",
    "            tensor_frame, resized_frame = process_frame(frame, target_size)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                prediction = model(tensor_frame)\n",
    "                prediction = prediction[0] if isinstance(prediction, tuple) else prediction\n",
    "                prediction = non_max_suppression(prediction, detection_threshold, nms_threshold)\n",
    "\n",
    "            if len(prediction[0]) > 0:\n",
    "                element = prediction[0][0]  # Take the first detection only\n",
    "                tracked_bbox = element[:4].cpu().numpy()\n",
    "                x, y, x2, y2 = tracked_bbox\n",
    "                # Scaling the bounding box coordinates to the original frame\n",
    "                scale_x = frame.shape[1] / target_size[0]\n",
    "                scale_y = frame.shape[0] / target_size[1]\n",
    "                x = int(x * scale_x) - padding\n",
    "                y = int(y * scale_y) - padding\n",
    "                x2 = int(x2 * scale_x) + padding\n",
    "                y2 = int(y2 * scale_y) + padding\n",
    "                # Ensure bbox is within frame boundaries\n",
    "                x = max(0, x)\n",
    "                y = max(0, y)\n",
    "                x2 = min(frame.shape[1], x2)\n",
    "                y2 = min(frame.shape[0], y2)\n",
    "                w, h = x2 - x, y2 - y\n",
    "                conf = element[4].cpu().numpy()\n",
    "                tracker = cv2.TrackerKCF_create()\n",
    "                tracker.init(frame, (x, y, w, h))\n",
    "                init_tracking = True\n",
    "                tracked_confidence = conf\n",
    "                tracking_stability = 1\n",
    "                track_history.append((x + w / 2, y + h / 2))  # Center of bbox\n",
    "                state_mean = np.array([x + w / 2, y + h / 2, 0, 0])  # Update state_mean\n",
    "                # Draw bounding box with confidence and label\n",
    "                label = f\"child_face {conf:.2f}\"\n",
    "                display_x, display_y = int(x / scale_x), int(y / scale_y)\n",
    "                display_w, display_h = int(w / scale_x), int(h / scale_y)\n",
    "                cv2.rectangle(resized_frame, (display_x, display_y), (display_x + display_w, display_y + display_h), (255, 0, 0), 1)\n",
    "                cv2.putText(resized_frame, label, (display_x, display_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "                save_tracked_image(frame, (x, y, w, h), output_dir, timestamp)\n",
    "            else:\n",
    "                init_tracking = False\n",
    "        else:\n",
    "            tensor_frame, resized_frame = process_frame(frame, target_size)\n",
    "\n",
    "        if init_tracking:\n",
    "            success, tracked_bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                tracking_stability += 1\n",
    "                if tracking_stability >= confidence_boost_threshold:\n",
    "                    tracked_confidence = min(tracked_confidence + 0.1, 1.0)  # Boost confidence\n",
    "                x, y, w, h = [int(v) for v in tracked_bbox]\n",
    "                x = max(0, x - padding)\n",
    "                y = max(0, y - padding)\n",
    "                x2 = min(frame.shape[1], x + w + 2 * padding)\n",
    "                y2 = min(frame.shape[0], y + h + 2 * padding)\n",
    "                w, h = x2 - x, y2 - y\n",
    "                track_history.append((x + w / 2, y + h / 2))  # Center of bbox\n",
    "                state_mean = np.array([x + w / 2, y + h / 2, 0, 0])  # Update state_mean\n",
    "                # Convert the bbox back to the resized frame scale\n",
    "                display_x, display_y = int(x / scale_x), int(y / scale_y)\n",
    "                display_w, display_h = int(w / scale_x), int(h / scale_y)\n",
    "                # Draw bounding box with confidence and label\n",
    "                cv2.rectangle(resized_frame, (display_x, display_y), (display_x + display_w, display_y + display_h), (255, 0, 0), 1)\n",
    "                cv2.putText(resized_frame, f\"child_face {tracked_confidence:.2f}\", (display_x, display_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "                save_tracked_image(frame, (x, y, w, h), output_dir, timestamp)\n",
    "            else:\n",
    "                # Use Kalman Filter to predict the next position\n",
    "                if len(track_history) >= 2 and state_mean is not None:\n",
    "                    predicted_pos, state_covariance = update_kalman(kf, state_mean, state_covariance, track_history[-1])\n",
    "                    x, y = int(predicted_pos[0] - w / 2), int(predicted_pos[1] - h / 2)\n",
    "                    track_history.append((predicted_pos[0], predicted_pos[1]))\n",
    "                    cv2.rectangle(resized_frame, (x, y), (x + w, y + h), (0, 255, 0), 1)  # Draw predicted bbox\n",
    "                    cv2.putText(resized_frame, \"Predicted\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)\n",
    "                    save_tracked_image(frame, (x, y, w, h), output_dir, timestamp)\n",
    "\n",
    "                tracking_stability = 0\n",
    "                tracked_confidence = max(tracked_confidence - 0.1, 0)  # Decrease confidence if tracking fails\n",
    "\n",
    "        # Resize frame for display purposes\n",
    "        display_frame = cv2.resize(resized_frame, (screen_width, screen_height))\n",
    "        cv2.imshow(\"Frame\", display_frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    if frame_count > 0:\n",
    "        last_timestamp = timestamps[frame_count - 1]\n",
    "        print(f\"Last timestamp processed for frame {frame_count}: {last_timestamp}\")\n",
    "    else:\n",
    "        print(\"No frames were processed.\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def process_videos(directory_path, model_path, save_base_dir):\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Directory path {directory_path} does not exist.\")\n",
    "        return\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model path {model_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    model = attempt_load(model_path, map_location='cuda')  # Load YOLOv7 model\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(('.mp4', '.avi', '.mov')):\n",
    "            video_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing video: {filename}\")\n",
    "\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Failed to open video {filename}\")\n",
    "                continue\n",
    "\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            if frame_count <= 0 or fps <= 0:\n",
    "                print(f\"Invalid video properties for {filename}\")\n",
    "                cap.release()\n",
    "                continue\n",
    "\n",
    "            print(f\"Frame Count (CAP_PROP_FRAME_COUNT): {frame_count}\")\n",
    "            timestamps = get_frame_timestamps(video_path)\n",
    "\n",
    "            ret, first_frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Failed to read first frame of {filename}\")\n",
    "                cap.release()\n",
    "                continue\n",
    "            cap.release()\n",
    "            winsound.Beep(440, 500)\n",
    "\n",
    "            video_save_dir = os.path.join(save_base_dir, os.path.splitext(filename)[0])\n",
    "            os.makedirs(video_save_dir, exist_ok=True)\n",
    "\n",
    "            detect_and_track(video_path, model, video_save_dir, timestamps)\n",
    "            print(f\"Finished processing {filename}.\")\n",
    "\n",
    "# Example usage\n",
    "process_videos(r\"C:\\Users\\ybr5070\\Documents\\PS4_fixed\", r\"C:\\Users\\ybr5070\\yolov7\\runs\\train\\exp4\\weights\\best.pt\", save_base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
